{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification of text documents using sparse features\n",
    "\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices.\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset. It will be\n",
    "automatically downloaded, then cached.\n",
    "\n",
    "The bar plot indicates the accuracy, training time (normalized) and test time\n",
    "(normalized) of each classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "all\n",
      "data loaded\n",
      "11314 documents - 22.055MB (training set)\n",
      "7532 documents - 13.801MB (test set)\n",
      "20 categories\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 8.393000s at 2.628MB/s\n",
      "n_samples: 11314, n_features: 129791\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 4.117000s at 3.352MB/s\n",
      "n_samples: 7532, n_features: 129791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = None\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')\n",
    "\n",
    "categories = data_train.target_names    # for case categories == None\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>From: leunggm@odin.control.utoronto.ca (Gary L...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>From: rpwhite@cs.nps.navy.mil (rpwhite)\\nSubje...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From: csyphers@uafhp..uark.edu (Chris Syphers)...</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From: nagle@netcom.com (John Nagle)\\nSubject: ...</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From: r4938585@joplin.biosci.arizona.edu (Doug...</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>From: jonh@david.wheaton.edu (Jonathan Hayward...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From: jimf@centerline.com (Jim Frost)\\nSubject...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>Distribution: world\\nFrom: elenay_creations@tc...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11285</th>\n",
       "      <td>From: re4@prism.gatech.EDU (RUSSELL EARNEST)\\n...</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11286</th>\n",
       "      <td>From: looper@cco.caltech.edu (Mark D. Looper)\\...</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11287</th>\n",
       "      <td>From: gballent@hudson.UVic.CA (Greg  Ballentin...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11288</th>\n",
       "      <td>From: cka52397@uxa.cso.uiuc.edu (OrioleFan@uiu...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>From: max@slinky.NYU.EDU (David Max)\\nSubject:...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>From: hades@coos.dartmouth.edu (Brian V. Hughe...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>From: c23reg@kocrsv01.delcoelect.com (Ron Gask...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>From: callison@uokmax.ecn.uoknor.edu (James P....</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>From: bigelos@hobo.ECE.ORST.EDU (Space Gigolo)...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>From: LMARSHA@cms.cc.wayne.edu (Laurie Marshal...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11295</th>\n",
       "      <td>From: gt5735a@prism.gatech.EDU (Mark Devaney)\\...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11296</th>\n",
       "      <td>From: pkeenan@s.psych.uiuc.edu (Patricia Keena...</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11297</th>\n",
       "      <td>From: CCMB &lt;CCMB@MUSICA.MCGILL.CA&gt;\\nSubject: W...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11298</th>\n",
       "      <td>From: cbetz@radioman.cray.com (Charles Betz  {...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11299</th>\n",
       "      <td>From: 2120788@hydra.maths.unsw.EDU.AU ()\\nSubj...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11300</th>\n",
       "      <td>From: aa888@freenet.carleton.ca (Mark Baker)\\n...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>From: zmed16@trc.amoco.com (Michael)\\nSubject:...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11302</th>\n",
       "      <td>From: rdippold@qualcomm.com (Ron \"Asbestos\" Di...</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11303</th>\n",
       "      <td>From: bchuang@css.itd.umich.edu (Ben Chuang)\\n...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>From: Pegasus@aaa.uoregon.edu (Pegasus)\\nSubje...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11305</th>\n",
       "      <td>From: shaig@composer.think.com (Shai Guday)\\nS...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>From: mrj@cs.su.oz.au (Mark James)\\nSubject: R...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11307</th>\n",
       "      <td>From: chein@eng.auburn.edu (Tsan Heui)\\nSubjec...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11308</th>\n",
       "      <td>From: adrian@ora.COM (Adrian Nye)\\nSubject: im...</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...   \n",
       "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...   \n",
       "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...   \n",
       "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...   \n",
       "5      From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...   \n",
       "6      From: bmdelane@quads.uchicago.edu (brian manni...   \n",
       "7      From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...   \n",
       "8      From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...   \n",
       "9      From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...   \n",
       "10     From: irwin@cmptrc.lonestar.org (Irwin Arnstei...   \n",
       "11     From: david@terminus.ericsson.se (David Bold)\\...   \n",
       "12     From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...   \n",
       "13     From: dbm0000@tm0006.lerc.nasa.gov (David B. M...   \n",
       "14     From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...   \n",
       "15     From: mathew <mathew@mantis.co.uk>\\nSubject: R...   \n",
       "16     From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...   \n",
       "17     From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...   \n",
       "18     From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...   \n",
       "19     From: abarden@tybse1.uucp (Ann Marie Barden)\\n...   \n",
       "20     From: keith@cco.caltech.edu (Keith Allan Schne...   \n",
       "21     From: leunggm@odin.control.utoronto.ca (Gary L...   \n",
       "22     From: rpwhite@cs.nps.navy.mil (rpwhite)\\nSubje...   \n",
       "23     From: csyphers@uafhp..uark.edu (Chris Syphers)...   \n",
       "24     From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...   \n",
       "25     From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...   \n",
       "26     From: nagle@netcom.com (John Nagle)\\nSubject: ...   \n",
       "27     From: r4938585@joplin.biosci.arizona.edu (Doug...   \n",
       "28     From: jonh@david.wheaton.edu (Jonathan Hayward...   \n",
       "29     From: jimf@centerline.com (Jim Frost)\\nSubject...   \n",
       "...                                                  ...   \n",
       "11284  Distribution: world\\nFrom: elenay_creations@tc...   \n",
       "11285  From: re4@prism.gatech.EDU (RUSSELL EARNEST)\\n...   \n",
       "11286  From: looper@cco.caltech.edu (Mark D. Looper)\\...   \n",
       "11287  From: gballent@hudson.UVic.CA (Greg  Ballentin...   \n",
       "11288  From: cka52397@uxa.cso.uiuc.edu (OrioleFan@uiu...   \n",
       "11289  From: max@slinky.NYU.EDU (David Max)\\nSubject:...   \n",
       "11290  From: hades@coos.dartmouth.edu (Brian V. Hughe...   \n",
       "11291  From: c23reg@kocrsv01.delcoelect.com (Ron Gask...   \n",
       "11292  From: callison@uokmax.ecn.uoknor.edu (James P....   \n",
       "11293  From: bigelos@hobo.ECE.ORST.EDU (Space Gigolo)...   \n",
       "11294  From: LMARSHA@cms.cc.wayne.edu (Laurie Marshal...   \n",
       "11295  From: gt5735a@prism.gatech.EDU (Mark Devaney)\\...   \n",
       "11296  From: pkeenan@s.psych.uiuc.edu (Patricia Keena...   \n",
       "11297  From: CCMB <CCMB@MUSICA.MCGILL.CA>\\nSubject: W...   \n",
       "11298  From: cbetz@radioman.cray.com (Charles Betz  {...   \n",
       "11299  From: 2120788@hydra.maths.unsw.EDU.AU ()\\nSubj...   \n",
       "11300  From: aa888@freenet.carleton.ca (Mark Baker)\\n...   \n",
       "11301  From: zmed16@trc.amoco.com (Michael)\\nSubject:...   \n",
       "11302  From: rdippold@qualcomm.com (Ron \"Asbestos\" Di...   \n",
       "11303  From: bchuang@css.itd.umich.edu (Ben Chuang)\\n...   \n",
       "11304  From: Pegasus@aaa.uoregon.edu (Pegasus)\\nSubje...   \n",
       "11305  From: shaig@composer.think.com (Shai Guday)\\nS...   \n",
       "11306  From: mrj@cs.su.oz.au (Mark James)\\nSubject: R...   \n",
       "11307  From: chein@eng.auburn.edu (Tsan Heui)\\nSubjec...   \n",
       "11308  From: adrian@ora.COM (Adrian Nye)\\nSubject: im...   \n",
       "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...   \n",
       "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...   \n",
       "11311  From: westes@netcom.com (Will Estes)\\nSubject:...   \n",
       "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...   \n",
       "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...   \n",
       "\n",
       "                         target  \n",
       "0                     rec.autos  \n",
       "1         comp.sys.mac.hardware  \n",
       "2         comp.sys.mac.hardware  \n",
       "3                 comp.graphics  \n",
       "4                     sci.space  \n",
       "5            talk.politics.guns  \n",
       "6                       sci.med  \n",
       "7      comp.sys.ibm.pc.hardware  \n",
       "8       comp.os.ms-windows.misc  \n",
       "9         comp.sys.mac.hardware  \n",
       "10              rec.motorcycles  \n",
       "11           talk.religion.misc  \n",
       "12        comp.sys.mac.hardware  \n",
       "13                    sci.space  \n",
       "14                 misc.forsale  \n",
       "15                  alt.atheism  \n",
       "16                comp.graphics  \n",
       "17                    rec.autos  \n",
       "18              sci.electronics  \n",
       "19               comp.windows.x  \n",
       "20                  alt.atheism  \n",
       "21             rec.sport.hockey  \n",
       "22                 misc.forsale  \n",
       "23      comp.os.ms-windows.misc  \n",
       "24        comp.sys.mac.hardware  \n",
       "25                comp.graphics  \n",
       "26              sci.electronics  \n",
       "27           rec.sport.baseball  \n",
       "28       soc.religion.christian  \n",
       "29                    rec.autos  \n",
       "...                         ...  \n",
       "11284     comp.sys.mac.hardware  \n",
       "11285        rec.sport.baseball  \n",
       "11286                 sci.space  \n",
       "11287          rec.sport.hockey  \n",
       "11288                 rec.autos  \n",
       "11289             comp.graphics  \n",
       "11290     comp.sys.mac.hardware  \n",
       "11291                 rec.autos  \n",
       "11292                 rec.autos  \n",
       "11293              misc.forsale  \n",
       "11294          rec.sport.hockey  \n",
       "11295  comp.sys.ibm.pc.hardware  \n",
       "11296        rec.sport.baseball  \n",
       "11297  comp.sys.ibm.pc.hardware  \n",
       "11298          rec.sport.hockey  \n",
       "11299     talk.politics.mideast  \n",
       "11300    soc.religion.christian  \n",
       "11301              misc.forsale  \n",
       "11302                 sci.crypt  \n",
       "11303     comp.sys.mac.hardware  \n",
       "11304        talk.religion.misc  \n",
       "11305     talk.politics.mideast  \n",
       "11306  comp.sys.ibm.pc.hardware  \n",
       "11307              misc.forsale  \n",
       "11308            comp.windows.x  \n",
       "11309                   sci.med  \n",
       "11310     comp.sys.mac.hardware  \n",
       "11311  comp.sys.ibm.pc.hardware  \n",
       "11312             comp.graphics  \n",
       "11313           rec.motorcycles  \n",
       "\n",
       "[11314 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['article'], data=data_train.data)\n",
    "df['target'] = np.array(data_train.target_names)[data_train.target]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 11.504s\n",
      "test time:  0.093s\n",
      "accuracy:   0.862\n",
      "dimensionality: 129791\n",
      "density: 0.999998\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.78      0.80       319\n",
      "           comp.graphics       0.76      0.82      0.79       389\n",
      " comp.os.ms-windows.misc       0.79      0.79      0.79       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.78      0.76       392\n",
      "   comp.sys.mac.hardware       0.83      0.86      0.85       385\n",
      "          comp.windows.x       0.89      0.78      0.83       395\n",
      "            misc.forsale       0.85      0.91      0.88       390\n",
      "               rec.autos       0.92      0.92      0.92       396\n",
      "         rec.motorcycles       0.96      0.95      0.96       398\n",
      "      rec.sport.baseball       0.92      0.95      0.93       397\n",
      "        rec.sport.hockey       0.96      0.98      0.97       399\n",
      "               sci.crypt       0.95      0.95      0.95       396\n",
      "         sci.electronics       0.81      0.77      0.79       393\n",
      "                 sci.med       0.91      0.88      0.90       396\n",
      "               sci.space       0.90      0.94      0.92       394\n",
      "  soc.religion.christian       0.84      0.94      0.89       398\n",
      "      talk.politics.guns       0.75      0.94      0.83       364\n",
      "   talk.politics.mideast       0.98      0.90      0.94       376\n",
      "      talk.politics.misc       0.86      0.61      0.71       310\n",
      "      talk.religion.misc       0.78      0.63      0.70       251\n",
      "\n",
      "             avg / total       0.86      0.86      0.86      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[248   1   0   2   0   0   1   0   2   0   0   1   1   9   7  25   0   1\n",
      "    0  21]\n",
      " [  2 320  10   8   6  15   3   0   1   2   1   3  10   0   5   1   0   0\n",
      "    0   2]\n",
      " [  0  16 312  28  11  10   1   1   0   5   1   1   1   1   3   0   0   0\n",
      "    0   3]\n",
      " [  0  11  22 305  18   2  10   2   0   2   0   0  18   0   1   0   0   0\n",
      "    0   1]\n",
      " [  0   5   5  20 332   1   9   0   0   1   0   0   8   2   0   0   2   0\n",
      "    0   0]\n",
      " [  0  36  31   3   4 310   3   0   1   0   0   1   0   1   4   0   1   0\n",
      "    0   0]\n",
      " [  0   2   1   9   7   0 353   5   2   1   0   1   7   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   4   1   1   8 363   4   2   0   0   7   1   0   0   1   0\n",
      "    2   0]\n",
      " [  0   0   0   1   0   0   3   8 380   1   0   0   3   1   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   1   0   0   1   4   1   1 376  12   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1   0   0   0   5 391   0   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   3   2   0   3   1   3   2   0   2   0 377   2   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   5   6  28  10   1   5   8   3   2   1   5 304   5   5   5   0   0\n",
      "    0   0]\n",
      " [  1   5   0   4   2   3   4   1   1   3   1   0   6 350   1   4   2   2\n",
      "    5   1]\n",
      " [  1   9   0   0   1   2   2   0   0   0   0   1   4   4 369   0   1   0\n",
      "    0   0]\n",
      " [  3   0   2   1   0   0   0   0   0   1   0   0   2   2   3 375   0   0\n",
      "    0   9]\n",
      " [  0   1   0   1   1   0   2   1   0   1   0   2   0   1   0   0 341   1\n",
      "   10   2]\n",
      " [ 10   2   0   0   1   2   0   1   0   5   1   0   0   1   1   6   1 338\n",
      "    7   0]\n",
      " [  3   1   0   0   2   0   1   0   0   0   0   3   0   4   6   1  95   1\n",
      "  188   5]\n",
      " [ 33   2   1   1   0   0   1   0   0   1   0   0   0   2   5  26  12   1\n",
      "    7 159]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 7.502s\n",
      "test time:  0.092s\n",
      "accuracy:   0.805\n",
      "dimensionality: 129791\n",
      "density: 0.095805\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.76      0.74       319\n",
      "           comp.graphics       0.73      0.76      0.74       389\n",
      " comp.os.ms-windows.misc       0.79      0.69      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.62      0.67       392\n",
      "   comp.sys.mac.hardware       0.76      0.82      0.79       385\n",
      "          comp.windows.x       0.78      0.78      0.78       395\n",
      "            misc.forsale       0.84      0.83      0.83       390\n",
      "               rec.autos       0.84      0.86      0.85       396\n",
      "         rec.motorcycles       0.91      0.92      0.91       398\n",
      "      rec.sport.baseball       0.88      0.89      0.88       397\n",
      "        rec.sport.hockey       0.93      0.96      0.94       399\n",
      "               sci.crypt       0.87      0.90      0.89       396\n",
      "         sci.electronics       0.72      0.71      0.72       393\n",
      "                 sci.med       0.82      0.81      0.82       396\n",
      "               sci.space       0.87      0.89      0.88       394\n",
      "  soc.religion.christian       0.80      0.89      0.84       398\n",
      "      talk.politics.guns       0.76      0.85      0.80       364\n",
      "   talk.politics.mideast       0.86      0.80      0.83       376\n",
      "      talk.politics.misc       0.75      0.59      0.66       310\n",
      "      talk.religion.misc       0.64      0.67      0.66       251\n",
      "\n",
      "             avg / total       0.80      0.80      0.80      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[241   2   0   0   0   0   0   1   2   1   1   1   2   4   8  20   2   1\n",
      "    0  33]\n",
      " [  3 294   9   7   6  19   5   1   1   2   0  10   9   7   7   5   0   2\n",
      "    0   2]\n",
      " [  1  16 273  23  18  15   4   2   0   5   4   3   3   9   5   2   0   0\n",
      "    6   5]\n",
      " [  2  21  21 243  24  10  10   2   5   2   0   5  31   2   3   2   2   4\n",
      "    1   2]\n",
      " [  1   5   6  15 316   4   8   1   3   1   1   1  12   1   1   1   3   1\n",
      "    4   0]\n",
      " [  0  32  25   5   3 309   4   2   1   3   0   1   4   2   2   0   1   1\n",
      "    0   0]\n",
      " [  0   5   2   6  11   2 323   7   3   5   3   2   8   2   2   2   1   3\n",
      "    1   2]\n",
      " [  0   1   1   2   4   2   8 340  10   3   1   4   8   5   2   1   1   0\n",
      "    3   0]\n",
      " [  1   0   1   1   3   0   3  10 365   1   0   2   1   4   1   0   0   3\n",
      "    2   0]\n",
      " [  2   1   1   0   3   2   4   5   0 353  11   2   2   4   0   1   0   5\n",
      "    1   0]\n",
      " [  1   0   0   0   3   3   0   0   1   5 383   0   0   0   0   0   1   1\n",
      "    1   0]\n",
      " [  2   4   1   1   5   4   4   2   2   1   0 358   1   1   2   0   3   2\n",
      "    2   1]\n",
      " [  3   5   0  27  10   6   4  11   2   5   1   8 278   8   6   7   1   5\n",
      "    3   3]\n",
      " [  4   3   2   3   4   4   3   9   0   3   1   0  10 321   3   7   2   6\n",
      "    6   5]\n",
      " [  1   8   1   1   1   4   1   6   1   0   1   0   5   8 350   3   0   1\n",
      "    1   1]\n",
      " [  9   0   1   1   1   2   0   0   0   2   0   0   3   4   2 355   0   1\n",
      "    3  14]\n",
      " [  3   1   1   2   1   2   1   2   2   1   4   7   2   0   0   2 308   4\n",
      "   12   9]\n",
      " [ 25   1   1   0   2   2   0   1   0   6   1   2   0   3   1  14   3 300\n",
      "   11   3]\n",
      " [  3   1   0   1   3   2   1   1   1   2   0   4   3   4   4   4  69   8\n",
      "  183  16]\n",
      " [ 28   4   1   0   0   4   1   4   1   0   0   0   2   2   4  17   8   1\n",
      "    5 169]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 9.657s\n",
      "test time:  0.099s\n",
      "accuracy:   0.855\n",
      "dimensionality: 129791\n",
      "density: 0.462989\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.81      0.79      0.80       319\n",
      "           comp.graphics       0.79      0.81      0.80       389\n",
      " comp.os.ms-windows.misc       0.81      0.74      0.77       394\n",
      "comp.sys.ibm.pc.hardware       0.70      0.73      0.71       392\n",
      "   comp.sys.mac.hardware       0.82      0.84      0.83       385\n",
      "          comp.windows.x       0.87      0.81      0.84       395\n",
      "            misc.forsale       0.84      0.91      0.87       390\n",
      "               rec.autos       0.93      0.92      0.92       396\n",
      "         rec.motorcycles       0.96      0.97      0.96       398\n",
      "      rec.sport.baseball       0.93      0.94      0.94       397\n",
      "        rec.sport.hockey       0.94      0.98      0.96       399\n",
      "               sci.crypt       0.92      0.95      0.94       396\n",
      "         sci.electronics       0.79      0.77      0.78       393\n",
      "                 sci.med       0.90      0.87      0.88       396\n",
      "               sci.space       0.89      0.93      0.91       394\n",
      "  soc.religion.christian       0.87      0.93      0.90       398\n",
      "      talk.politics.guns       0.75      0.92      0.82       364\n",
      "   talk.politics.mideast       0.98      0.89      0.93       376\n",
      "      talk.politics.misc       0.82      0.59      0.69       310\n",
      "      talk.religion.misc       0.75      0.66      0.70       251\n",
      "\n",
      "             avg / total       0.86      0.85      0.85      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[252   1   0   2   0   0   1   0   3   1   0   1   1   6   7  19   0   0\n",
      "    0  25]\n",
      " [  1 315   7   9   7  16   5   3   0   2   2   6   7   0   4   2   0   1\n",
      "    0   2]\n",
      " [  0  17 291  39   9  14   2   1   1   2   1   2   4   2   5   0   0   0\n",
      "    2   2]\n",
      " [  0  11  21 285  26   3  14   2   0   1   0   1  24   0   1   0   0   1\n",
      "    2   0]\n",
      " [  0   6   4  16 325   2  13   0   0   2   1   0   9   3   0   0   2   0\n",
      "    2   0]\n",
      " [  0  27  30   4   3 319   4   0   0   0   1   0   2   2   2   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   8   7   0 354   6   2   2   0   1   6   1   1   0   0   0\n",
      "    1   0]\n",
      " [  0   1   0   4   1   1   9 363   6   1   0   0   6   1   0   0   1   0\n",
      "    2   0]\n",
      " [  0   0   0   1   0   0   2   3 385   1   0   0   2   1   1   0   1   0\n",
      "    0   1]\n",
      " [  0   0   1   0   0   0   2   2   1 375  12   0   1   1   0   0   0   0\n",
      "    2   0]\n",
      " [  0   0   0   0   1   1   0   0   0   5 392   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   1   1   0   3   2   3   2   0   1   1 377   2   0   0   0   2   0\n",
      "    0   0]\n",
      " [  0   5   3  30   9   1   5   4   3   1   1  14 301   7   5   2   0   0\n",
      "    0   2]\n",
      " [  3   5   0   3   2   3   3   2   1   5   2   0  10 345   2   2   2   1\n",
      "    4   1]\n",
      " [  2   6   0   0   1   3   2   0   0   0   1   0   3   5 367   1   0   0\n",
      "    2   1]\n",
      " [  3   0   2   2   0   0   0   0   0   1   0   0   1   2   3 371   0   0\n",
      "    0  13]\n",
      " [  0   0   0   2   1   0   1   1   1   1   0   5   0   1   1   0 336   1\n",
      "   10   3]\n",
      " [ 16   2   0   0   0   1   0   1   0   3   1   0   0   1   1   5   3 335\n",
      "    7   0]\n",
      " [  4   3   0   0   1   1   1   0   0   0   2   3   0   4   6   2  91   2\n",
      "  184   6]\n",
      " [ 31   0   1   1   0   0   2   0   0   1   0   0   0   3   5  23  12   1\n",
      "    6 165]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.016s\n",
      "test time:  10.462s\n",
      "accuracy:   0.717\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.68      0.80      0.73       319\n",
      "           comp.graphics       0.56      0.65      0.60       389\n",
      " comp.os.ms-windows.misc       0.62      0.67      0.64       394\n",
      "comp.sys.ibm.pc.hardware       0.54      0.63      0.58       392\n",
      "   comp.sys.mac.hardware       0.62      0.62      0.62       385\n",
      "          comp.windows.x       0.72      0.66      0.69       395\n",
      "            misc.forsale       0.58      0.54      0.56       390\n",
      "               rec.autos       0.77      0.73      0.75       396\n",
      "         rec.motorcycles       0.84      0.86      0.85       398\n",
      "      rec.sport.baseball       0.74      0.80      0.77       397\n",
      "        rec.sport.hockey       0.83      0.89      0.86       399\n",
      "               sci.crypt       0.81      0.86      0.83       396\n",
      "         sci.electronics       0.66      0.53      0.59       393\n",
      "                 sci.med       0.81      0.59      0.68       396\n",
      "               sci.space       0.75      0.81      0.78       394\n",
      "  soc.religion.christian       0.80      0.82      0.81       398\n",
      "      talk.politics.guns       0.75      0.78      0.77       364\n",
      "   talk.politics.mideast       0.87      0.85      0.86       376\n",
      "      talk.politics.misc       0.74      0.65      0.70       310\n",
      "      talk.religion.misc       0.67      0.57      0.61       251\n",
      "\n",
      "             avg / total       0.72      0.72      0.72      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[255   1   1   4   0   2   1   0   1   1   0   2   1   9   7  16   0   0\n",
      "    0  18]\n",
      " [  6 251  20  12   9  23   6   6   4   8   6   8   7   2   9   1   4   3\n",
      "    3   1]\n",
      " [  4  23 263  32   7  14  11   4   1   9   0   6   3   1   8   2   1   1\n",
      "    2   2]\n",
      " [  3  20  31 246  22   8  19   2   2   2   0   4  17   1   9   0   0   1\n",
      "    3   2]\n",
      " [  4  14  16  35 237   5  20   5   3   9   4   4   7   3   5   3   0   5\n",
      "    4   2]\n",
      " [  2  37  30  10  12 259   6   1   8   4   2   4   8   2   9   0   0   1\n",
      "    0   0]\n",
      " [  5  10  21  33  33   9 210   9   2  12   4   0  18   6   2   3   0   4\n",
      "    4   5]\n",
      " [  0  10   5  14  13   7  12 291   7   4   3   4   8   4   1   1   7   2\n",
      "    1   2]\n",
      " [  0   1   0   4   5   3   9  13 342   3   1   2   4   1   1   1   2   2\n",
      "    3   1]\n",
      " [  7   6   0   3   3   0   7  12   3 318  24   1   2   0   2   0   3   2\n",
      "    3   1]\n",
      " [  4   1   1   3   1   3   5   0   3  12 354   1   2   3   2   0   0   1\n",
      "    0   3]\n",
      " [  4   4   3   4   7   2   2   2   3   2   3 339   1   3   3   3   6   1\n",
      "    4   0]\n",
      " [  8  19  15  24  15   3  18  12  11  11   7  10 209   7  11   2   1   4\n",
      "    2   4]\n",
      " [  8   9   7  11   9   4  23   4   9  10   5   7  17 233   2  11   2   9\n",
      "    9   7]\n",
      " [  1  20   3   4   0   3   3   7   1   7   3   4   6   3 318   0   6   1\n",
      "    4   0]\n",
      " [ 16   2   3   1   1   3   2   1   2   3   4   1   1   2   6 328   2   1\n",
      "    6  13]\n",
      " [  0   4   2   6   2   5   1   4   4   5   0  12   1   2   9   2 285   3\n",
      "   11   6]\n",
      " [  5   4   1   1   3   1   0   1   1   2   5   2   3   1   2  18   1 320\n",
      "    5   0]\n",
      " [  1   8   2   2   2   2   8   3   0   1   3   8   0   0  10   1  48   3\n",
      "  203   5]\n",
      " [ 42   2   1   3   2   2   1   2   0   5   1   1   1   3   6  16  11   2\n",
      "    7 143]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 139.766s\n",
      "test time:  1.718s\n",
      "accuracy:   0.788\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.69      0.72       319\n",
      "           comp.graphics       0.63      0.72      0.67       389\n",
      " comp.os.ms-windows.misc       0.67      0.76      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.69      0.69      0.69       392\n",
      "   comp.sys.mac.hardware       0.76      0.79      0.78       385\n",
      "          comp.windows.x       0.79      0.75      0.77       395\n",
      "            misc.forsale       0.76      0.88      0.82       390\n",
      "               rec.autos       0.83      0.83      0.83       396\n",
      "         rec.motorcycles       0.92      0.91      0.91       398\n",
      "      rec.sport.baseball       0.86      0.91      0.89       397\n",
      "        rec.sport.hockey       0.90      0.94      0.92       399\n",
      "               sci.crypt       0.90      0.92      0.91       396\n",
      "         sci.electronics       0.74      0.57      0.65       393\n",
      "                 sci.med       0.86      0.77      0.81       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.74      0.95      0.83       398\n",
      "      talk.politics.guns       0.67      0.88      0.76       364\n",
      "   talk.politics.mideast       0.94      0.80      0.86       376\n",
      "      talk.politics.misc       0.79      0.51      0.62       310\n",
      "      talk.religion.misc       0.79      0.39      0.53       251\n",
      "\n",
      "             avg / total       0.79      0.79      0.78      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[221   1   1   0   3   2   5   1   0   6   1   2   1   5   4  38   4   4\n",
      "    1  19]\n",
      " [  1 279  24   9  13  30   6   1   2   5   0   2   4   2   7   1   1   1\n",
      "    1   0]\n",
      " [  0  26 298  25  15   9   0   4   1   1   0   2   2   2   4   1   0   3\n",
      "    0   1]\n",
      " [  1  19  42 272  16   5   7   7   0   2   0   2  15   1   3   0   0   0\n",
      "    0   0]\n",
      " [  0   8  13  24 304   3  12   2   1   2   0   0  13   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0  32  41   6   4 295   8   0   0   1   0   2   1   0   5   0   0   0\n",
      "    0   0]\n",
      " [  0   7   2   9   8   1 345   3   1   4   1   1   3   1   3   1   0   0\n",
      "    0   0]\n",
      " [  1   7   1   2   4   1  14 328  16   2   0   1   7   1   2   1   6   0\n",
      "    2   0]\n",
      " [  1   1   0   2   2   1   7  12 362   2   0   1   2   3   1   0   1   0\n",
      "    0   0]\n",
      " [  0   3   0   1   2   0   4   3   1 362  17   0   2   1   0   1   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   3   0   5   0   0  13 374   0   0   1   1   0   0   0\n",
      "    1   0]\n",
      " [  0   3   4   4   1   2   1   0   0   2   0 365   6   0   0   0   4   0\n",
      "    4   0]\n",
      " [  5  22  14  30  15  10  13  12   7   5   3  14 225   3   9   4   0   1\n",
      "    0   1]\n",
      " [  4  12   3   4   4   5  11   8   1   3   3   1  17 304   3   3   3   1\n",
      "    6   0]\n",
      " [  0  11   0   0   1   2   4   1   1   5   1   2   2   5 351   1   2   0\n",
      "    5   0]\n",
      " [  5   1   1   2   1   1   3   1   0   0   0   0   1   0   2 377   0   1\n",
      "    0   2]\n",
      " [  0   2   0   2   2   2   4   3   1   2   0   9   1   1   1   1 320   1\n",
      "   12   0]\n",
      " [ 26   0   0   0   0   3   2   4   0   2   8   2   2   6   3   6   7 299\n",
      "    3   3]\n",
      " [  1   2   0   2   1   0   2   2   0   1   2   1   0   9  11   4 113   2\n",
      "  157   0]\n",
      " [ 30   3   1   0   0   1   1   1   0   1   4   0   0   8   4  68  19   5\n",
      "    6  99]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 11.384s\n",
      "test time:  0.073s\n",
      "accuracy:   0.861\n",
      "dimensionality: 129791\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.79      0.81       319\n",
      "           comp.graphics       0.76      0.82      0.79       389\n",
      " comp.os.ms-windows.misc       0.80      0.77      0.78       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.78      0.75       392\n",
      "   comp.sys.mac.hardware       0.83      0.86      0.85       385\n",
      "          comp.windows.x       0.88      0.78      0.83       395\n",
      "            misc.forsale       0.84      0.91      0.87       390\n",
      "               rec.autos       0.93      0.91      0.92       396\n",
      "         rec.motorcycles       0.96      0.96      0.96       398\n",
      "      rec.sport.baseball       0.92      0.95      0.94       397\n",
      "        rec.sport.hockey       0.95      0.98      0.97       399\n",
      "               sci.crypt       0.94      0.95      0.95       396\n",
      "         sci.electronics       0.83      0.77      0.80       393\n",
      "                 sci.med       0.92      0.88      0.90       396\n",
      "               sci.space       0.90      0.94      0.92       394\n",
      "  soc.religion.christian       0.86      0.94      0.90       398\n",
      "      talk.politics.guns       0.74      0.92      0.82       364\n",
      "   talk.politics.mideast       0.98      0.91      0.94       376\n",
      "      talk.politics.misc       0.85      0.60      0.70       310\n",
      "      talk.religion.misc       0.76      0.63      0.69       251\n",
      "\n",
      "             avg / total       0.86      0.86      0.86      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[251   1   0   2   0   0   1   0   2   0   0   1   1   7   8  21   0   1\n",
      "    0  23]\n",
      " [  1 318   8   9   7  18   4   1   1   3   1   4   7   0   4   1   0   0\n",
      "    0   2]\n",
      " [  0  19 304  33   9  11   1   0   1   3   1   1   2   2   4   0   0   0\n",
      "    0   3]\n",
      " [  0  12  21 306  19   1  12   2   0   1   0   0  17   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   5   4  15 333   1  11   1   0   2   0   0   9   1   0   0   2   0\n",
      "    1   0]\n",
      " [  1  37  31   3   3 309   3   0   0   0   1   0   1   1   4   0   1   0\n",
      "    0   0]\n",
      " [  0   1   1   6   8   0 356   6   2   1   0   1   6   1   0   0   0   0\n",
      "    1   0]\n",
      " [  0   1   0   5   1   1  10 359   6   2   0   0   7   1   0   0   1   0\n",
      "    2   0]\n",
      " [  0   0   0   1   0   0   4   6 383   1   0   0   0   0   1   0   1   0\n",
      "    0   1]\n",
      " [  0   0   1   0   0   0   4   2   1 377  12   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   1   0   0   0   5 391   0   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   4   1   3   2   0   2   0 378   1   0   0   0   1   1\n",
      "    0   0]\n",
      " [  0   6   5  33  11   0   3   4   3   1   0  10 304   6   3   2   0   0\n",
      "    1   1]\n",
      " [  2   5   0   3   2   2   5   2   1   4   2   0   8 349   1   2   2   2\n",
      "    3   1]\n",
      " [  1   6   0   0   1   3   2   0   0   0   1   1   3   4 369   0   1   0\n",
      "    2   0]\n",
      " [  3   0   2   1   0   0   0   0   0   1   0   0   2   1   3 375   0   0\n",
      "    0  10]\n",
      " [  0   2   1   1   1   0   2   1   0   1   0   3   0   1   1   0 336   1\n",
      "   10   3]\n",
      " [  8   1   1   0   0   2   0   1   0   3   1   0   0   1   1   6   2 343\n",
      "    6   0]\n",
      " [  3   1   0   0   2   0   2   0   0   0   0   4   0   4   6   1  94   2\n",
      "  186   5]\n",
      " [ 31   2   1   1   0   0   1   1   0   1   0   0   0   2   3  29  13   1\n",
      "    7 158]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 7.593s\n",
      "test time:  0.108s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Gary\\WinPython\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\scikit_learn-0.18-py2.7-win-amd64.egg\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n",
      "D:\\Gary\\WinPython\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\scikit_learn-0.18-py2.7-win-amd64.egg\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:   0.859\n",
      "dimensionality: 129791\n",
      "density: 0.390593\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.78      0.80       319\n",
      "           comp.graphics       0.76      0.81      0.79       389\n",
      " comp.os.ms-windows.misc       0.78      0.76      0.77       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.77      0.75       392\n",
      "   comp.sys.mac.hardware       0.83      0.86      0.85       385\n",
      "          comp.windows.x       0.89      0.79      0.83       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.93      0.90      0.91       396\n",
      "         rec.motorcycles       0.96      0.96      0.96       398\n",
      "      rec.sport.baseball       0.91      0.95      0.93       397\n",
      "        rec.sport.hockey       0.95      0.98      0.97       399\n",
      "               sci.crypt       0.93      0.95      0.94       396\n",
      "         sci.electronics       0.82      0.76      0.79       393\n",
      "                 sci.med       0.91      0.88      0.90       396\n",
      "               sci.space       0.89      0.94      0.92       394\n",
      "  soc.religion.christian       0.86      0.93      0.90       398\n",
      "      talk.politics.guns       0.73      0.93      0.82       364\n",
      "   talk.politics.mideast       0.97      0.92      0.95       376\n",
      "      talk.politics.misc       0.86      0.60      0.70       310\n",
      "      talk.religion.misc       0.75      0.62      0.68       251\n",
      "\n",
      "             avg / total       0.86      0.86      0.86      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[249   1   0   3   0   0   1   0   2   0   0   2   1   7   8  22   0   1\n",
      "    0  22]\n",
      " [  2 317  12   7   5  19   3   1   1   3   1   4   6   0   5   1   0   0\n",
      "    0   2]\n",
      " [  0  20 299  29  13  12   2   1   0   4   1   2   1   1   4   0   0   0\n",
      "    0   5]\n",
      " [  0  12  24 300  19   1   9   3   0   2   0   0  19   0   1   0   1   0\n",
      "    0   1]\n",
      " [  0   5   4  14 333   1  13   1   0   2   0   0   9   0   0   0   2   0\n",
      "    1   0]\n",
      " [  1  34  32   3   2 311   3   0   0   0   1   1   1   2   3   0   1   0\n",
      "    0   0]\n",
      " [  0   3   1   8   9   0 350   6   2   1   0   1   6   2   0   0   0   0\n",
      "    1   0]\n",
      " [  0   1   1   4   1   0  10 358   7   1   0   1   8   1   0   0   1   0\n",
      "    2   0]\n",
      " [  0   0   0   1   0   0   3   6 383   1   0   0   0   1   1   0   1   0\n",
      "    0   1]\n",
      " [  0   0   1   0   0   0   3   2   0 378  12   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6 393   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   2   1   3   2   0   2   0 378   2   0   0   1   1   1\n",
      "    0   0]\n",
      " [  1   6   5  29  11   1   3   5   3   2   0  11 300   6   5   1   1   1\n",
      "    1   1]\n",
      " [  2   5   0   2   2   2   5   1   1   3   2   0   7 350   2   3   2   2\n",
      "    3   2]\n",
      " [  1   6   0   0   1   0   2   0   0   0   1   1   4   4 372   0   1   0\n",
      "    1   0]\n",
      " [  4   0   2   1   0   0   0   0   0   1   0   0   2   3   3 372   0   0\n",
      "    0  10]\n",
      " [  0   0   1   1   0   0   2   0   1   1   0   3   0   1   1   0 339   1\n",
      "   10   3]\n",
      " [  7   1   0   0   0   2   0   1   0   4   1   0   0   1   1   5   2 346\n",
      "    5   0]\n",
      " [  3   1   0   0   1   1   2   0   0   0   1   3   0   3   6   1  96   2\n",
      "  185   5]\n",
      " [ 35   2   1   1   0   0   1   0   0   3   0   0   0   1   5  25  14   1\n",
      "    7 155]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 9.777s\n",
      "test time:  0.083s\n",
      "accuracy:   0.827\n",
      "dimensionality: 129791\n",
      "density: 0.002413\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.78      0.74      0.76       319\n",
      "           comp.graphics       0.72      0.78      0.75       389\n",
      " comp.os.ms-windows.misc       0.75      0.77      0.76       394\n",
      "comp.sys.ibm.pc.hardware       0.69      0.77      0.72       392\n",
      "   comp.sys.mac.hardware       0.79      0.84      0.82       385\n",
      "          comp.windows.x       0.89      0.75      0.81       395\n",
      "            misc.forsale       0.83      0.87      0.85       390\n",
      "               rec.autos       0.87      0.87      0.87       396\n",
      "         rec.motorcycles       0.91      0.94      0.92       398\n",
      "      rec.sport.baseball       0.91      0.92      0.91       397\n",
      "        rec.sport.hockey       0.95      0.96      0.95       399\n",
      "               sci.crypt       0.91      0.92      0.91       396\n",
      "         sci.electronics       0.75      0.69      0.72       393\n",
      "                 sci.med       0.89      0.83      0.86       396\n",
      "               sci.space       0.86      0.92      0.89       394\n",
      "  soc.religion.christian       0.87      0.92      0.89       398\n",
      "      talk.politics.guns       0.72      0.90      0.80       364\n",
      "   talk.politics.mideast       0.96      0.84      0.90       376\n",
      "      talk.politics.misc       0.77      0.59      0.67       310\n",
      "      talk.religion.misc       0.67      0.59      0.63       251\n",
      "\n",
      "             avg / total       0.83      0.83      0.83      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[236   1   0   1   1   0   2   0   2   2   1   1   1   8  11  17   0   2\n",
      "    1  32]\n",
      " [  3 302  13  10   9  13   4   1   3   3   1   6   9   1   7   1   1   0\n",
      "    2   0]\n",
      " [  0  20 302  28  11  10   2   1   4   0   2   2   5   1   2   2   1   0\n",
      "    0   1]\n",
      " [  0  11  29 300  17   2  12   2   0   0   0   3  15   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   5   3  29 323   0   8   0   2   0   0   0   9   2   0   0   3   0\n",
      "    0   1]\n",
      " [  0  40  36   4   5 295   2   2   0   0   1   0   3   0   5   1   0   0\n",
      "    1   0]\n",
      " [  0   1   1  10   9   0 338   6   4   1   1   1   9   2   3   2   1   0\n",
      "    0   1]\n",
      " [  0   4   1   2   3   1   8 345   8   2   0   0  16   1   0   1   2   0\n",
      "    2   0]\n",
      " [  1   1   0   1   2   0   3  10 374   1   0   0   1   2   0   1   0   0\n",
      "    1   0]\n",
      " [  0   2   0   0   0   1   4   3   0 365  11   2   1   3   2   0   1   2\n",
      "    0   0]\n",
      " [  0   0   0   0   4   0   4   0   0   8 382   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   4   3   3   1   0   4   4   0   0   0 363   5   0   1   1   3   0\n",
      "    4   0]\n",
      " [  2   5   6  36  16   2   4  13   7   3   3   8 272   5   5   3   0   0\n",
      "    1   2]\n",
      " [  1   9   1   9   2   1   6   1   1   6   0   3   6 329   4   3   1   1\n",
      "    7   5]\n",
      " [  1   8   0   1   2   2   2   1   2   2   0   2   3   4 361   1   1   0\n",
      "    1   0]\n",
      " [  7   0   1   0   0   0   1   1   0   0   0   0   2   1   3 366   0   2\n",
      "    2  12]\n",
      " [  0   2   1   1   0   0   2   4   0   0   0   3   0   3   1   0 326   3\n",
      "   11   7]\n",
      " [ 11   1   0   1   1   3   0   2   3   4   1   1   3   0   6   3   3 317\n",
      "   11   5]\n",
      " [  2   2   0   1   1   0   1   0   1   2   0   3   1   4   7   1  93   3\n",
      "  182   6]\n",
      " [ 38   0   4   0   0   0   1   1   0   2   0   0   3   3   3  20  18   1\n",
      "    8 149]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 18.610s\n",
      "test time:  0.101s\n",
      "accuracy:   0.792\n",
      "dimensionality: 129791\n",
      "density: 0.001155\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.69      0.71       319\n",
      "           comp.graphics       0.72      0.74      0.73       389\n",
      " comp.os.ms-windows.misc       0.71      0.79      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.68      0.70      0.69       392\n",
      "   comp.sys.mac.hardware       0.75      0.78      0.77       385\n",
      "          comp.windows.x       0.84      0.71      0.77       395\n",
      "            misc.forsale       0.82      0.83      0.83       390\n",
      "               rec.autos       0.85      0.84      0.84       396\n",
      "         rec.motorcycles       0.86      0.92      0.89       398\n",
      "      rec.sport.baseball       0.88      0.91      0.89       397\n",
      "        rec.sport.hockey       0.93      0.94      0.94       399\n",
      "               sci.crypt       0.92      0.92      0.92       396\n",
      "         sci.electronics       0.73      0.57      0.64       393\n",
      "                 sci.med       0.81      0.80      0.81       396\n",
      "               sci.space       0.87      0.90      0.89       394\n",
      "  soc.religion.christian       0.83      0.90      0.86       398\n",
      "      talk.politics.guns       0.67      0.86      0.75       364\n",
      "   talk.politics.mideast       0.77      0.82      0.80       376\n",
      "      talk.politics.misc       0.78      0.57      0.66       310\n",
      "      talk.religion.misc       0.59      0.45      0.51       251\n",
      "\n",
      "             avg / total       0.79      0.79      0.79      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[220   2   0   1   7   0   4   1   2   2   4   2   0  14   9  29   0   2\n",
      "    1  19]\n",
      " [  2 288  16   9  13  23   4   2   3   3   1   2   6   1   3   1   1   6\n",
      "    2   3]\n",
      " [  0  15 310  21  11   7   0   1   3   2   2   2   4   1   2   2   1   5\n",
      "    0   5]\n",
      " [  2  10  34 275  21   3   6   6   1   0   1   2  22   4   1   0   0   2\n",
      "    0   2]\n",
      " [  3   5  10  31 302   1  10   0   2   1   0   0   7   5   1   0   0   5\n",
      "    1   1]\n",
      " [  0  40  44   5   4 279   1   2   1   1   1   0   1   2   6   0   1   6\n",
      "    1   0]\n",
      " [  0   2   3  14   8   1 325   5   6   1   1   1   8   3   5   1   1   5\n",
      "    0   0]\n",
      " [  0   4   1   1   3   0   8 331  12   4   0   1  13   2   2   0   6   5\n",
      "    1   2]\n",
      " [  1   1   0   1   1   0   6  11 367   2   0   0   2   2   0   0   2   0\n",
      "    0   2]\n",
      " [  0   2   1   0   0   1   5   0   1 361  12   2   1   3   2   0   0   2\n",
      "    0   4]\n",
      " [  1   0   1   0   5   0   4   0   0  10 377   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   0   2   1   1   1   1   3   1   1   0 366   6   2   0   1   5   2\n",
      "    2   1]\n",
      " [  2   9  11  35  19   9   3  15  13   5   4  11 224   6   6   1   2  11\n",
      "    3   4]\n",
      " [  5  10   2   5   1   3   6   3   2   4   0   1   5 318   1   4   1  11\n",
      "    6   8]\n",
      " [  0   7   0   0   2   2   2   1   2   3   0   1   0   8 355   1   2   4\n",
      "    3   1]\n",
      " [  9   0   2   1   0   1   1   0   0   2   0   0   2   3   1 359   0   5\n",
      "    2  10]\n",
      " [  0   2   0   1   1   0   4   4   4   2   0   6   2   3   2   0 312   7\n",
      "    9   5]\n",
      " [ 10   1   0   1   1   2   1   1   3   4   3   1   2   0   9   5  10 308\n",
      "    7   7]\n",
      " [  1   1   0   1   1   0   2   1   2   0   0   1   1  10   0   1 102   4\n",
      "  177   5]\n",
      " [ 45   0   2   0   0   0   3   2   4   3   0   0   0   6   3  30  21   8\n",
      "   10 114]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 27.592s\n",
      "test time:  0.111s\n",
      "accuracy:   0.850\n",
      "dimensionality: 129791\n",
      "density: 0.032102\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.77      0.79       319\n",
      "           comp.graphics       0.77      0.78      0.77       389\n",
      " comp.os.ms-windows.misc       0.75      0.78      0.76       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.74      0.74       392\n",
      "   comp.sys.mac.hardware       0.82      0.86      0.84       385\n",
      "          comp.windows.x       0.88      0.77      0.82       395\n",
      "            misc.forsale       0.85      0.89      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.95      0.96      0.95       398\n",
      "      rec.sport.baseball       0.90      0.95      0.93       397\n",
      "        rec.sport.hockey       0.95      0.97      0.96       399\n",
      "               sci.crypt       0.92      0.96      0.94       396\n",
      "         sci.electronics       0.80      0.74      0.77       393\n",
      "                 sci.med       0.90      0.89      0.90       396\n",
      "               sci.space       0.88      0.93      0.91       394\n",
      "  soc.religion.christian       0.85      0.94      0.89       398\n",
      "      talk.politics.guns       0.72      0.92      0.81       364\n",
      "   talk.politics.mideast       0.96      0.90      0.93       376\n",
      "      talk.politics.misc       0.86      0.60      0.70       310\n",
      "      talk.religion.misc       0.78      0.58      0.66       251\n",
      "\n",
      "             avg / total       0.85      0.85      0.85      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[247   1   0   1   0   0   2   0   1   1   0   3   2  10   8  25   0   1\n",
      "    0  17]\n",
      " [  1 302  15   7   7  19   3   2   3   3   2   5   8   0   6   1   0   3\n",
      "    1   1]\n",
      " [  0  15 306  29  12   9   0   1   0   6   1   2   0   2   4   1   0   0\n",
      "    0   6]\n",
      " [  0   9  31 292  18   3  10   4   0   0   0   1  21   0   1   0   0   1\n",
      "    0   1]\n",
      " [  0   5   4  21 332   1   9   1   0   1   0   0   9   0   0   0   2   0\n",
      "    0   0]\n",
      " [  1  35  34   4   4 305   2   0   1   0   1   0   1   2   4   0   1   0\n",
      "    0   0]\n",
      " [  0   2   2   7   8   0 349   5   2   1   1   1   9   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1   3   2   0   9 355   7   1   0   0  11   1   0   0   3   0\n",
      "    2   0]\n",
      " [  0   0   0   0   1   0   3   6 382   1   0   0   1   1   0   0   0   0\n",
      "    2   1]\n",
      " [  0   0   0   0   0   0   4   2   0 377  12   0   0   1   0   0   0   1\n",
      "    0   0]\n",
      " [  0   1   0   0   1   0   2   0   0   6 389   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   2   0   2   1   1   2   0   2   0 379   1   0   0   1   3   0\n",
      "    1   0]\n",
      " [  1   4  10  28  10   3   4   6   5   3   1  11 289   6   7   3   1   1\n",
      "    0   0]\n",
      " [  2   4   0   1   3   2   4   1   1   3   1   0   5 354   2   3   3   2\n",
      "    2   3]\n",
      " [  1   9   0   0   1   0   2   1   0   0   0   2   2   5 368   0   1   0\n",
      "    2   0]\n",
      " [  5   0   2   1   0   0   0   0   0   1   0   0   2   1   4 375   0   0\n",
      "    0   7]\n",
      " [  0   1   1   1   0   0   1   2   0   3   0   5   0   2   1   0 334   1\n",
      "    9   3]\n",
      " [  8   3   0   0   1   5   0   1   0   5   1   0   0   1   1   3   2 340\n",
      "    5   0]\n",
      " [  3   1   0   0   1   0   2   1   1   0   1   3   0   3   5   1  98   3\n",
      "  185   2]\n",
      " [ 41   0   1   0   0   0   2   0   0   3   0   0   0   2   4  29  16   1\n",
      "    7 145]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.145s\n",
      "test time:  0.104s\n",
      "accuracy:   0.787\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.58      0.68       319\n",
      "           comp.graphics       0.58      0.81      0.67       389\n",
      " comp.os.ms-windows.misc       0.75      0.77      0.76       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.70      0.71       392\n",
      "   comp.sys.mac.hardware       0.83      0.81      0.82       385\n",
      "          comp.windows.x       0.85      0.72      0.78       395\n",
      "            misc.forsale       0.80      0.86      0.83       390\n",
      "               rec.autos       0.86      0.87      0.87       396\n",
      "         rec.motorcycles       0.97      0.91      0.94       398\n",
      "      rec.sport.baseball       0.95      0.91      0.93       397\n",
      "        rec.sport.hockey       0.96      0.92      0.94       399\n",
      "               sci.crypt       0.97      0.77      0.86       396\n",
      "         sci.electronics       0.44      0.78      0.56       393\n",
      "                 sci.med       0.93      0.63      0.75       396\n",
      "               sci.space       0.88      0.85      0.86       394\n",
      "  soc.religion.christian       0.79      0.90      0.84       398\n",
      "      talk.politics.guns       0.74      0.84      0.79       364\n",
      "   talk.politics.mideast       0.98      0.80      0.88       376\n",
      "      talk.politics.misc       0.69      0.60      0.64       310\n",
      "      talk.religion.misc       0.65      0.55      0.60       251\n",
      "\n",
      "             avg / total       0.81      0.79      0.79      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[184   9   0   0   1   0   1   4   2   0   0   1  15   8   1  46   1   2\n",
      "    4  40]\n",
      " [  1 314  11   6  10  17   4   0   0   0   0   0  17   0   6   0   0   0\n",
      "    0   3]\n",
      " [  0  29 304  25   6   7   1   2   0   0   0   0  11   0   3   0   0   0\n",
      "    2   4]\n",
      " [  0  24  23 274   9   2   9   3   0   0   0   0  44   0   4   0   0   0\n",
      "    0   0]\n",
      " [  0   7   8  23 312   1  11   0   0   2   0   0  18   0   2   0   0   0\n",
      "    1   0]\n",
      " [  0  47  42   6   1 285   3   0   0   0   0   0   8   0   3   0   0   0\n",
      "    0   0]\n",
      " [  0   5   2  18   7   0 335   6   1   0   0   0  16   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   6   0   0   0   1   9 345   2   0   0   0  26   0   3   0   0   0\n",
      "    2   1]\n",
      " [  0   2   0   0   1   0   6  13 362   0   0   0  12   0   0   0   0   0\n",
      "    2   0]\n",
      " [  0   4   0   0   2   0   6   2   1 360  13   0   8   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   3   0   0   8   0   3   0   0  10 366   0   7   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0  15   2   0   3   2   0   0   1   0   0 306  46   1   3   0   5   0\n",
      "   12   0]\n",
      " [  1  21  11  24   8   2   5   5   1   0   0   3 306   1   4   0   0   0\n",
      "    1   0]\n",
      " [  3  24   0   0   2   3  11   7   2   0   0   0  75 251   2   6   0   1\n",
      "    7   2]\n",
      " [  0  15   0   0   2   2   3   2   0   1   0   0  24   2 334   0   0   0\n",
      "    9   0]\n",
      " [  2   5   1   0   0   1   1   0   0   1   0   0  14   0   2 357   0   0\n",
      "    3  11]\n",
      " [  0   1   0   1   1   0   4   6   0   3   0   4  16   2   1   0 306   1\n",
      "   12   6]\n",
      " [  7   5   0   0   0  11   1   3   1   2   1   0  14   1   0   3   4 301\n",
      "   19   3]\n",
      " [  0   3   0   0   1   0   2   3   1   0   0   1  11   0   7   1  87   0\n",
      "  187   6]\n",
      " [ 25   6   1   0   1   0   2   0   0   0   0   0   8   4   3  39  12   1\n",
      "   10 139]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.226s\n",
      "test time:  0.083s\n",
      "accuracy:   0.837\n",
      "dimensionality: 129791\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.80      0.81       319\n",
      "           comp.graphics       0.68      0.74      0.71       389\n",
      " comp.os.ms-windows.misc       0.77      0.59      0.67       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.77      0.71       392\n",
      "   comp.sys.mac.hardware       0.83      0.84      0.84       385\n",
      "          comp.windows.x       0.82      0.79      0.81       395\n",
      "            misc.forsale       0.81      0.79      0.80       390\n",
      "               rec.autos       0.90      0.91      0.91       396\n",
      "         rec.motorcycles       0.94      0.96      0.95       398\n",
      "      rec.sport.baseball       0.96      0.94      0.95       397\n",
      "        rec.sport.hockey       0.95      0.98      0.96       399\n",
      "               sci.crypt       0.87      0.93      0.90       396\n",
      "         sci.electronics       0.79      0.77      0.78       393\n",
      "                 sci.med       0.90      0.84      0.87       396\n",
      "               sci.space       0.87      0.92      0.89       394\n",
      "  soc.religion.christian       0.85      0.94      0.90       398\n",
      "      talk.politics.guns       0.76      0.91      0.83       364\n",
      "   talk.politics.mideast       0.97      0.94      0.96       376\n",
      "      talk.politics.misc       0.77      0.63      0.69       310\n",
      "      talk.religion.misc       0.77      0.63      0.69       251\n",
      "\n",
      "             avg / total       0.84      0.84      0.84      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[254   0   0   3   0   1   0   0   1   1   0   1   0   5   4  23   2   3\n",
      "    3  18]\n",
      " [  0 289  12  14   8  25   9   0   0   1   0   7  14   0   7   1   0   1\n",
      "    0   1]\n",
      " [  1  31 232  55   8  27   9   0   0   1   1   7   5   3   4   4   0   0\n",
      "    4   2]\n",
      " [  0   9  21 300  20   3  11   2   0   1   0   2  21   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   6   7  12 323   2   9   4   0   2   1   4  11   2   1   0   0   0\n",
      "    1   0]\n",
      " [  0  45  11  10   4 312   2   1   1   0   0   3   1   1   3   0   1   0\n",
      "    0   0]\n",
      " [  0   4   5  25  11   0 310  11   7   0   3   0   8   3   2   0   1   0\n",
      "    0   0]\n",
      " [  0   1   1   4   0   0  12 361   6   0   0   0   6   1   1   0   1   0\n",
      "    2   0]\n",
      " [  0   0   0   1   1   0   2   7 384   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   4   1   2 372  12   0   0   0   3   1   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   3 391   1   0   1   0   1   1   0\n",
      "    0   0]\n",
      " [  1   4   1   2   2   1   3   3   0   0   0 370   1   3   2   0   3   0\n",
      "    0   0]\n",
      " [  1  10   7  24   6   2   8   3   2   0   0  13 301   8   6   0   0   1\n",
      "    1   0]\n",
      " [  2  12   0   2   1   2   5   3   0   3   0   3   6 331   4   6   2   2\n",
      "   10   2]\n",
      " [  0   7   0   4   1   3   0   1   1   0   0   1   3   4 361   1   1   0\n",
      "    6   0]\n",
      " [  3   2   1   1   0   0   0   0   0   1   2   0   0   2   2 376   0   0\n",
      "    2   6]\n",
      " [  0   0   0   0   0   0   1   0   2   1   0   5   1   2   1   0 333   0\n",
      "   12   6]\n",
      " [  4   1   0   0   0   1   0   0   0   0   1   0   0   0   0   1   2 354\n",
      "   11   1]\n",
      " [  6   1   0   0   1   0   0   2   0   0   1   5   0   1   9   2  75   2\n",
      "  195  10]\n",
      " [ 34   1   2   0   0   0   0   1   0   0   0   1   0   2   5  26  14   1\n",
      "    6 158]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.229s\n",
      "test time:  0.236s\n",
      "accuracy:   0.771\n",
      "dimensionality: 129791\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.83      0.79       319\n",
      "           comp.graphics       0.55      0.74      0.63       389\n",
      " comp.os.ms-windows.misc       0.79      0.07      0.13       394\n",
      "comp.sys.ibm.pc.hardware       0.51      0.76      0.61       392\n",
      "   comp.sys.mac.hardware       0.66      0.83      0.74       385\n",
      "          comp.windows.x       0.80      0.71      0.75       395\n",
      "            misc.forsale       0.56      0.88      0.68       390\n",
      "               rec.autos       0.87      0.87      0.87       396\n",
      "         rec.motorcycles       0.90      0.94      0.92       398\n",
      "      rec.sport.baseball       0.96      0.90      0.93       397\n",
      "        rec.sport.hockey       0.97      0.92      0.95       399\n",
      "               sci.crypt       0.88      0.85      0.86       396\n",
      "         sci.electronics       0.70      0.73      0.72       393\n",
      "                 sci.med       0.91      0.71      0.80       396\n",
      "               sci.space       0.87      0.83      0.85       394\n",
      "  soc.religion.christian       0.90      0.89      0.90       398\n",
      "      talk.politics.guns       0.83      0.84      0.83       364\n",
      "   talk.politics.mideast       0.98      0.83      0.90       376\n",
      "      talk.politics.misc       0.74      0.59      0.66       310\n",
      "      talk.religion.misc       0.69      0.63      0.66       251\n",
      "\n",
      "             avg / total       0.80      0.77      0.76      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[265   1   0   3   1   0   3   0   2   1   0   1   1   2   1  14   1   2\n",
      "    1  20]\n",
      " [  1 287   0  18  14  20  19   0   0   0   0   8  10   0   9   0   0   1\n",
      "    1   1]\n",
      " [  1  73  27 163  35  33  22   2   2   1   0  11  11   2   4   1   1   0\n",
      "    4   1]\n",
      " [  0   9   3 297  28   4  20   0   0   0   0   2  28   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   6   1  14 321   1  20   1   0   0   0   1  13   1   5   0   0   0\n",
      "    1   0]\n",
      " [  0  70   2  12   9 279  15   0   1   0   0   3   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0  22   8   1 342   5   0   0   0   0   4   2   0   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   2   1   0  27 346   8   0   0   1   6   1   0   0   0   0\n",
      "    3   0]\n",
      " [  0   1   0   0   2   0   7  10 374   0   0   0   2   0   0   0   0   0\n",
      "    2   0]\n",
      " [  1   0   0   2   2   0  12   1   1 358  11   0   2   2   2   0   0   0\n",
      "    3   0]\n",
      " [  1   1   1   0   4   0  10   0   3   7 368   1   1   0   0   0   0   0\n",
      "    2   0]\n",
      " [  1  10   0   8  12   3  11   2   0   0   0 336   5   2   3   0   2   0\n",
      "    1   0]\n",
      " [  1  16   0  27  11   1  23   3   2   0   0  14 288   4   3   0   0   0\n",
      "    0   0]\n",
      " [  3  14   0   4  15   1  25   8  10   1   0   0  18 282   4   2   2   1\n",
      "    6   0]\n",
      " [  3  14   0   3   4   3  18   3   0   0   0   0  10   4 326   0   0   0\n",
      "    6   0]\n",
      " [  4   4   0   4   4   0   8   0   2   1   0   0   2   1   1 356   0   0\n",
      "    1  10]\n",
      " [  2   1   0   0   4   1  10   4   3   0   0   3   3   3   0   0 304   0\n",
      "   15  11]\n",
      " [ 21   2   0   4   5   0   9   0   1   2   0   0   0   1   0   4   1 311\n",
      "   13   2]\n",
      " [  9   4   0   0   3   1   5   6   5   2   0   2   3   1  10   0  51   0\n",
      "  182  26]\n",
      " [ 39   4   0   2   0   0   6   6   0   0   0   0   0   1   5  19   5   1\n",
      "    4 159]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 11.821s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Gary\\WinPython\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\scikit_learn-0.18-py2.7-win-amd64.egg\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "D:\\Gary\\WinPython\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\scikit_learn-0.18-py2.7-win-amd64.egg\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test time:  0.107s\n",
      "accuracy:   0.843\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.78      0.78      0.78       319\n",
      "           comp.graphics       0.74      0.78      0.76       389\n",
      " comp.os.ms-windows.misc       0.79      0.78      0.79       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.75      0.74       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.86      0.76      0.81       395\n",
      "            misc.forsale       0.83      0.89      0.86       390\n",
      "               rec.autos       0.90      0.90      0.90       396\n",
      "         rec.motorcycles       0.94      0.94      0.94       398\n",
      "      rec.sport.baseball       0.93      0.93      0.93       397\n",
      "        rec.sport.hockey       0.96      0.97      0.96       399\n",
      "               sci.crypt       0.93      0.93      0.93       396\n",
      "         sci.electronics       0.78      0.75      0.76       393\n",
      "                 sci.med       0.88      0.87      0.88       396\n",
      "               sci.space       0.89      0.93      0.91       394\n",
      "  soc.religion.christian       0.85      0.92      0.89       398\n",
      "      talk.politics.guns       0.72      0.92      0.81       364\n",
      "   talk.politics.mideast       0.96      0.86      0.91       376\n",
      "      talk.politics.misc       0.82      0.59      0.68       310\n",
      "      talk.religion.misc       0.71      0.60      0.65       251\n",
      "\n",
      "             avg / total       0.84      0.84      0.84      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[248   1   0   1   0   0   1   0   2   0   0   1   1   8   7  24   0   1\n",
      "    0  24]\n",
      " [  1 305   9   7   9  19   4   2   0   1   2   6  11   2   6   1   1   2\n",
      "    0   1]\n",
      " [  1  21 308  28  11  10   2   1   1   2   0   1   0   0   3   0   0   0\n",
      "    0   5]\n",
      " [  0  11  24 293  23   3  13   3   0   0   0   2  18   0   1   0   0   0\n",
      "    1   0]\n",
      " [  0   8   3  19 320   1  11   0   0   0   0   0  12   5   1   0   4   0\n",
      "    1   0]\n",
      " [  0  42  30   6   4 302   1   0   1   0   1   0   2   0   4   0   1   1\n",
      "    0   0]\n",
      " [  0   1   2  11   9   0 347   6   3   0   0   1   8   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   0   1  10 355   9   1   0   1  11   1   1   0   1   0\n",
      "    2   0]\n",
      " [  0   0   0   1   1   1   3   7 376   2   1   0   2   1   1   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   5   3   1 371  12   0   2   1   1   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   3   1   2   0   0   6 387   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   3   2   2   1   3   1   1   2   0 369   3   4   0   1   2   0\n",
      "    0   1]\n",
      " [  1   5   4  31   8   2   5   7   6   4   1   7 293   9   4   3   0   0\n",
      "    2   1]\n",
      " [  2   3   1   3   2   3   4   3   0   5   0   0   4 346   3   3   3   3\n",
      "    4   4]\n",
      " [  0   7   0   0   2   0   1   1   0   1   0   1   4   7 366   0   1   0\n",
      "    3   0]\n",
      " [  6   0   2   1   0   0   1   0   0   0   0   0   2   2   3 368   0   0\n",
      "    0  13]\n",
      " [  0   2   0   2   0   0   1   1   1   1   0   2   0   1   0   0 335   2\n",
      "   11   5]\n",
      " [ 17   1   0   0   1   6   0   1   0   4   1   4   1   2   2   1   3 325\n",
      "    7   0]\n",
      " [  3   1   0   0   0   0   1   1   0   0   0   3   1   3   5   2  99   3\n",
      "  182   6]\n",
      " [ 39   0   1   0   0   1   2   1   0   0   0   0   1   1   4  29  14   1\n",
      "    7 150]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAIxCAYAAAArEoxrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwEuSJEk9YgIvSZIk9cj/B6LXDfs9N0IDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2939fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    " \n",
    "    #     if feature_names is not None:\n",
    "    #         print(\"top 10 keywords per class:\")\n",
    "    #         for i, category in enumerate(categories):\n",
    "    #             top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    #             print(trim(\"%s: %s\"\n",
    "    #                   % (category, \" \".join(feature_names[top10]))))\n",
    "    print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=categories))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
       "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline([\n",
    "    ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "    ('classification', LinearSVC())\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
